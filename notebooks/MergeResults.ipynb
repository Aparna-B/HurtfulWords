{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/h/haoran/projects/HurtfulWords/data/models/finetuned/debiasing_finetuning_10.0/baseline_clinical_BERT_1_epoch_512/phenotype_first/\"\n",
    "# OUTPUT_DIR = \"/h/haoran/projects/HurtfulWords/data/models/finetuned/debiasing_finetuning_1.0/baseline_clinical_BERT_1_epoch_512/phenotype_first/\"\n",
    "# OUTPUT_DIR = \"/h/haoran/projects/HurtfulWords/data/models/finetuned/baseline_clinical_BERT_1_epoch_512/phenotype_first/\"\n",
    "HIDE_CIs = True\n",
    "SIG = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = ['all', 'gender' ,'language_to_use', 'insurance', 'ethnicity_to_use'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_significant(lower, upper):\n",
    "    return -1*((lower < 0) & (upper < 0)) + ((lower >0) & (upper > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5a0c6899604ac7a244a89745621b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = {i: [] for i in sheets}\n",
    "for subdir, dirs, files in tqdm(os.walk(OUTPUT_DIR)):\n",
    "    for split in dirs:\n",
    "        for sheet in sheets:\n",
    "            base_dir = os.path.join(OUTPUT_DIR, split)\n",
    "            file_name = os.path.join(base_dir, 'results.xlsx')\n",
    "            df = pd.read_excel(file_name, index_col=0, sheet_name = sheet)\n",
    "            dfs[sheet].append(df)          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf(mat):\n",
    "    return scipy.stats.t.interval(SIG, mat.shape[0]-1, loc=np.mean(mat, axis= 0), scale=scipy.stats.sem(mat, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/haoran/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1910: RuntimeWarning: invalid value encountered in multiply\n",
      "  lower_bound = self.a * scale + loc\n",
      "/h/haoran/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1911: RuntimeWarning: invalid value encountered in multiply\n",
      "  upper_bound = self.b * scale + loc\n",
      "/h/haoran/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in less\n",
      "  \n",
      "/h/haoran/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(index = dfs['all'][0].index)\n",
    "for sheet in sheets:    \n",
    "    if sheet == 'all':\n",
    "        columns = ['all_auroc', 'all_auprc','all_specificity', 'all_recall']        \n",
    "        for i in columns:\n",
    "            temp = []\n",
    "            for split in dfs[sheet]:\n",
    "                temp.append(split[i])\n",
    "            res[i] = np.mean(np.array(temp), axis = 0)\n",
    "            res[i+ '_std'] = np.std(np.array(temp), axis = 0)\n",
    "\n",
    "    elif sheet == 'gender':\n",
    "        columns = {\n",
    "                'gender==\"F\"_dgap_max':'Parity Gap (F-M)',\n",
    "                   'gender==\"F\"_egap_positive_max':'Recall Gap',\n",
    "                   'gender==\"F\"_egap_negative_max':'Specificity Gap',\n",
    "                  }\n",
    "        for i in columns:\n",
    "            n = i.replace('gender==', '')\n",
    "            temp = []\n",
    "            for split in dfs[sheet]:\n",
    "                temp.append(split[i])\n",
    "            res[n] = np.mean(np.array(temp), axis = 0)\n",
    "            lower, upper = conf(np.array(temp))\n",
    "            res[n + '_lower'] = lower\n",
    "            res[n + '_upper'] = upper            \n",
    "            res[n + '_sig'] = gap_significant(lower, upper)                 \n",
    "\n",
    "    elif sheet == 'insurance':                            \n",
    "        columns = []\n",
    "        for i in ['Medicare', 'Private', 'Medicaid']:\n",
    "#             for j in ['precision', 'recall', 'specificity', 'pred_prevalence', 'actual_prevalence',\n",
    "#                      'nsamples', 'dgap_max', 'egap_positive_max', 'egap_negative_max']:\n",
    "            for j in ['dgap_max', 'egap_positive_max', 'egap_negative_max']:\n",
    "                columns.append(\n",
    "                    'insurance==\"%s\"_%s'%(i,j)\n",
    "                )\n",
    "        for i in columns:\n",
    "            temp = []\n",
    "            n = i.replace('insurance==', '')\n",
    "            for split in dfs[sheet]:\n",
    "                temp.append(split[i])\n",
    "            res[n] = np.mean(np.array(temp), axis = 0)\n",
    "            lower, upper = conf(np.array(temp))\n",
    "            res[n + '_lower'] = lower\n",
    "            res[n + '_upper'] = upper            \n",
    "            res[n + '_sig'] = gap_significant(lower, upper)      \n",
    "\n",
    "    elif sheet == 'language_to_use':\n",
    "        columns = {'language_to_use==\"English\"_dgap_max' : 'Parity Gap (E-O)', \n",
    "                   'language_to_use==\"English\"_egap_positive_max' : 'Recall Gap', \n",
    "                   'language_to_use==\"English\"_egap_negative_max' : 'Specificity Gap' }\n",
    "        for i in columns:\n",
    "            temp = []\n",
    "            n = i.replace('language_to_use==', '')\n",
    "            for split in dfs[sheet]:\n",
    "                temp.append(split[i])\n",
    "            res[n] = np.mean(np.array(temp), axis = 0)\n",
    "            lower, upper = conf(np.array(temp))\n",
    "            res[n + '_lower'] = lower\n",
    "            res[n + '_upper'] = upper            \n",
    "            res[n + '_sig'] = gap_significant(lower, upper)      \n",
    "\n",
    "    elif sheet == 'ethnicity_to_use':\n",
    "        columns = []\n",
    "        for i in ['WHITE', 'BLACK', 'ASIAN', 'HISPANIC/LATINO', 'OTHER']:\n",
    "#             for j in ['precision', 'recall', 'specificity', 'pred_prevalence', 'actual_prevalence',\n",
    "#                      'nsamples', 'dgap_max', 'egap_positive_max', 'egap_negative_max']:\n",
    "            for j in ['dgap_max', 'egap_positive_max', 'egap_negative_max']:\n",
    "                columns.append(\n",
    "                    'ethnicity_to_use==\"%s\"_%s'%(i,j)\n",
    "                )\n",
    "        for i in columns:\n",
    "            temp = []\n",
    "            n = i.replace('ethnicity_to_use==', '')\n",
    "            for split in dfs[sheet]:\n",
    "                temp.append(split[i])\n",
    "            res[n] = np.mean(np.array(temp), axis = 0)\n",
    "            lower, upper = conf(np.array(temp))\n",
    "            res[n + '_lower'] = lower\n",
    "            res[n + '_upper'] = upper            \n",
    "            res[n + '_sig'] = gap_significant(lower, upper)      \n",
    "        \n",
    "#     dfs[sheet] = res.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>Total Sig</th>\n",
       "      <th>Total For</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"F\"_egap_positive_max_sig</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"English\"_egap_positive_max_sig</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Medicare\"_egap_positive_max_sig</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Private\"_egap_positive_max_sig</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Medicaid\"_egap_positive_max_sig</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"WHITE\"_egap_positive_max_sig</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"BLACK\"_egap_positive_max_sig</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"ASIAN\"_egap_positive_max_sig</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"HISPANIC/LATINO\"_egap_positive_max_sig</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"OTHER\"_egap_positive_max_sig</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      type  Total Sig  Total For\n",
       "0                \"F\"_egap_positive_max_sig         14         11\n",
       "1          \"English\"_egap_positive_max_sig         13          1\n",
       "2         \"Medicare\"_egap_positive_max_sig         23         22\n",
       "3          \"Private\"_egap_positive_max_sig         14          0\n",
       "4         \"Medicaid\"_egap_positive_max_sig         25          2\n",
       "5            \"WHITE\"_egap_positive_max_sig         10          9\n",
       "6            \"BLACK\"_egap_positive_max_sig          3          0\n",
       "7            \"ASIAN\"_egap_positive_max_sig          5          5\n",
       "8  \"HISPANIC/LATINO\"_egap_positive_max_sig          7          1\n",
       "9            \"OTHER\"_egap_positive_max_sig          1          0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for i in res.columns:\n",
    "    if 'sig' in i and 'egap_positive' in i:\n",
    "        negative = (res[i] == -1).sum()\n",
    "        positive = (res[i] == 1).sum()\n",
    "        data.append([i,negative+ positive, positive])\n",
    "pd.DataFrame(data, columns = ['type','Total Sig','Total For'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6762327490370332"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['all_auroc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
